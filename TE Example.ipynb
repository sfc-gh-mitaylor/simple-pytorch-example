{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e00444c5-38f9-416b-94ef-c26f52712d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.functions import sproc, col\n",
    "import snowflake.snowpark.functions as F\n",
    "import snowflake.snowpark.types as T\n",
    "\n",
    "from snowflake.snowpark.types import PandasDataFrameType, IntegerType, StringType, FloatType, Variant\n",
    "from snowflake.snowpark.exceptions import SnowparkSQLException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f6376c4e-9de4-4347-a710-91182e916dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Warehouse ASYNC_WH successfully created.')]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading Snowflake Connection Details\n",
    "snowflake_connection_cfg = json.loads(open(\"/Users/mitaylor/Documents/creds/creds.json\").read())\n",
    "\n",
    "# Creating Snowpark Session\n",
    "session = Session.builder.configs(snowflake_connection_cfg).create()\n",
    "\n",
    "# Create a fresh & new schema\n",
    "session.sql(\"CREATE OR REPLACE DATABASE TE_DEMO\").collect()\n",
    "session.sql('''CREATE OR REPLACE STAGE TE_STAGE''').collect()\n",
    "session.sql(\"CREATE OR REPLACE WAREHOUSE ASYNC_WH WITH WAREHOUSE_SIZE='X-SMALL'\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "20ccc17b-2b7b-47d8-878b-0129aac4b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "X,y = make_classification(n_samples=1000, n_features=5, n_classes=2)\n",
    "X = np.array(X, dtype=np.float32)\n",
    "df = pd.DataFrame(X)\n",
    "feature_cols = [\"COL\" + str(i) for i in df.columns]\n",
    "df.columns = feature_cols\n",
    "\n",
    "df['HH'] = np.random.randint(5, size=len(df))\n",
    "df['GEO'] = [str(i) for i in list(np.random.randint(5, size=len(df)))]\n",
    "df['CONTRACT_ID'] = np.random.randint(7, size=len(df))\n",
    "df['ACTUAL'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "373b5ade-cda8-43de-950b-5db8a589c78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COL0</th>\n",
       "      <th>COL1</th>\n",
       "      <th>COL2</th>\n",
       "      <th>COL3</th>\n",
       "      <th>COL4</th>\n",
       "      <th>HH</th>\n",
       "      <th>GEO</th>\n",
       "      <th>CONTRACT_ID</th>\n",
       "      <th>ACTUAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.406002</td>\n",
       "      <td>0.017545</td>\n",
       "      <td>-0.943426</td>\n",
       "      <td>1.218018</td>\n",
       "      <td>1.010194</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.620726</td>\n",
       "      <td>0.652450</td>\n",
       "      <td>0.389985</td>\n",
       "      <td>0.131251</td>\n",
       "      <td>-0.312289</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.950217</td>\n",
       "      <td>-0.774260</td>\n",
       "      <td>0.172066</td>\n",
       "      <td>1.005823</td>\n",
       "      <td>0.019462</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.728694</td>\n",
       "      <td>-1.905334</td>\n",
       "      <td>1.629292</td>\n",
       "      <td>-0.663405</td>\n",
       "      <td>-1.505705</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.430774</td>\n",
       "      <td>-0.045657</td>\n",
       "      <td>1.665727</td>\n",
       "      <td>0.251562</td>\n",
       "      <td>-1.385133</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-1.952966</td>\n",
       "      <td>0.455013</td>\n",
       "      <td>2.250839</td>\n",
       "      <td>-1.526417</td>\n",
       "      <td>-2.181286</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1.054075</td>\n",
       "      <td>0.332765</td>\n",
       "      <td>-1.189076</td>\n",
       "      <td>0.775039</td>\n",
       "      <td>1.147134</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-1.396142</td>\n",
       "      <td>1.188223</td>\n",
       "      <td>1.640246</td>\n",
       "      <td>-1.150232</td>\n",
       "      <td>-1.595847</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-1.271618</td>\n",
       "      <td>0.337766</td>\n",
       "      <td>0.150457</td>\n",
       "      <td>1.497205</td>\n",
       "      <td>0.119486</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-0.429867</td>\n",
       "      <td>0.506280</td>\n",
       "      <td>1.286648</td>\n",
       "      <td>-1.834702</td>\n",
       "      <td>-1.406499</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         COL0      COL1      COL2      COL3      COL4  HH GEO  CONTRACT_ID  \\\n",
       "0    0.406002  0.017545 -0.943426  1.218018  1.010194   0   1            6   \n",
       "1   -0.620726  0.652450  0.389985  0.131251 -0.312289   3   3            6   \n",
       "2   -0.950217 -0.774260  0.172066  1.005823  0.019462   3   0            5   \n",
       "3   -1.728694 -1.905334  1.629292 -0.663405 -1.505705   3   3            6   \n",
       "4   -2.430774 -0.045657  1.665727  0.251562 -1.385133   3   0            6   \n",
       "..        ...       ...       ...       ...       ...  ..  ..          ...   \n",
       "995 -1.952966  0.455013  2.250839 -1.526417 -2.181286   4   4            3   \n",
       "996  1.054075  0.332765 -1.189076  0.775039  1.147134   1   1            5   \n",
       "997 -1.396142  1.188223  1.640246 -1.150232 -1.595847   4   1            6   \n",
       "998 -1.271618  0.337766  0.150457  1.497205  0.119486   3   2            0   \n",
       "999 -0.429867  0.506280  1.286648 -1.834702 -1.406499   1   0            2   \n",
       "\n",
       "     ACTUAL  \n",
       "0         1  \n",
       "1         0  \n",
       "2         1  \n",
       "3         0  \n",
       "4         0  \n",
       "..      ...  \n",
       "995       0  \n",
       "996       1  \n",
       "997       0  \n",
       "998       1  \n",
       "999       0  \n",
       "\n",
       "[1000 rows x 9 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dbfbcbfa-a4f8-4566-b0b6-248cd6f5c420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.snowpark.table.Table at 0x7fbd9b6527d0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.write_pandas(df, table_name='DUMMY_DATASET', auto_create_table=True, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1e9902f4-ee6f-4dc5-bf00-77762dde1e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='View V1 successfully created.')]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql('''CREATE OR REPLACE VIEW v1 AS SELECT COL0, COL1, COL2, COL3, COL4, TO_DATE('2018-01-01') AS DATE, HH, GEO, CONTRACT_ID, ACTUAL FROM DUMMY_DATASET;''').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a96f2ba3-e02c-4a3d-9c9a-fcb7d514aeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"COL0\"               |\"COL1\"                |\"COL2\"               |\"COL3\"               |\"COL4\"                |\"DATE\"      |\"HH\"  |\"GEO\"  |\"CONTRACT_ID\"  |\"ACTUAL\"  |\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|0.4060015082359314   |0.017545100301504135  |-0.943425714969635   |1.2180180549621582   |1.0101940631866455    |2018-01-01  |0     |1      |6              |1         |\n",
      "|-0.6207262873649597  |0.6524500846862793    |0.3899853527545929   |0.13125106692314148  |-0.3122890889644623   |2018-01-01  |3     |3      |6              |0         |\n",
      "|-0.9502167701721191  |-0.7742597460746765   |0.17206589877605438  |1.0058226585388184   |0.019461724907159805  |2018-01-01  |3     |0      |5              |1         |\n",
      "|-1.7286940813064575  |-1.9053336381912231   |1.6292924880981445   |-0.663404643535614   |-1.5057049989700317   |2018-01-01  |3     |3      |6              |0         |\n",
      "|-2.4307737350463867  |-0.04565710201859474  |1.6657270193099976   |0.25156155228614807  |-1.3851332664489746   |2018-01-01  |3     |0      |6              |0         |\n",
      "|1.5409146547317505   |0.03249052166938782   |-0.2717345952987671  |-1.6449065208435059  |-0.0401015430688858   |2018-01-01  |1     |4      |6              |0         |\n",
      "|-0.9274356365203857  |-1.3840055465698242   |0.7461720108985901   |-0.1135781779885292  |-0.6580132842063904   |2018-01-01  |3     |3      |5              |0         |\n",
      "|2.106201648712158    |-1.9493657350540161   |-0.53163081407547    |-1.9448732137680054  |0.13276517391204834   |2018-01-01  |4     |3      |2              |0         |\n",
      "|0.814350426197052    |0.6026967763900757    |-1.3520399332046509  |1.4197056293487549   |1.3936711549758911    |2018-01-01  |0     |4      |5              |1         |\n",
      "|0.48184311389923096  |-1.883745789527893    |0.7564903497695923   |-2.1082589626312256  |-0.9977450370788574   |2018-01-01  |3     |0      |4              |0         |\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session.table('v1').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0099fd77-b383-4321-9891-4675e1faf2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.types import PandasDataFrameType, IntegerType, StringType, FloatType, TimeType, DateType\n",
    "\n",
    "class UDTF_Model_Train:\n",
    "    def end_partition(self, df_pandas):\n",
    "        from snowflake.ml.modeling.xgboost import XGBClassifier   \n",
    "\n",
    "        # When a UDTF ingest a dataframe it does not know what the columns are, you need to tell it (appended with _ to avoid namespace clashes when we come to yield)\n",
    "        df_pandas.columns = ['COL0_', 'COL1_', 'COL2_', 'COL3_', 'COL4_', 'DATE_', 'HH_', 'GEO_', 'CONTRACT_ID_', 'ACTUAL_']\n",
    "\n",
    "        # This is generally not necessary but xgboost model can be temperemental with dtypes so it can be helpful to \"force\" it\n",
    "        df_pandas = df_pandas.astype({'COL0_': 'float32'})\n",
    "        df_pandas = df_pandas.astype({'COL1_': 'float32'})\n",
    "        df_pandas = df_pandas.astype({'COL2_': 'float32'})\n",
    "        df_pandas = df_pandas.astype({'COL3_': 'float32'})\n",
    "        df_pandas = df_pandas.astype({'COL4_': 'float32'})\n",
    "        df_pandas = df_pandas.astype({'ACTUAL_': 'float32'})\n",
    "        \n",
    "        try:\n",
    "            # Define the XGBRegressor using Snowpark ML (exact same library under the hood, but an abstraction to make it easier to work with Snowflake\n",
    "            final_model = XGBClassifier(\n",
    "                input_cols=['COL0_', 'COL1_', 'COL2_', 'COL3_', 'COL4_'],\n",
    "                label_cols=['ACTUAL_'],\n",
    "                output_cols=['FORECAST_']\n",
    "            )\n",
    "\n",
    "            # note you can also run on a snowpark dataframe directly\n",
    "            final_model.fit(df_pandas)\n",
    "\n",
    "            # no need to create a predict column, that is handled in the output_cols field above\n",
    "            df_pandas = final_model.predict(df_pandas) \n",
    "            df_print = df_pandas[[\"DATE_\",\"HH_\",\"ACTUAL_\",\"GEO_\",\"CONTRACT_ID_\", \"FORECAST_\"]]                      \n",
    "        except Exception as e:\n",
    "            df_print = pd.DataFrame(columns=[\"DATE\",\"HH\",\"ACTUAL\",\"GEO\",\"CONTRACT_ID\", \"FORECAST\"])\n",
    "\n",
    "        #yield statement is per partition, effectively the end result is a stack of all the yield statements alltogether \n",
    "        yield df_print\n",
    "\n",
    "UDTF_Model_Train.end_partition._sf_vectorized_input = pd.DataFrame\n",
    "\n",
    "udtf_model_inf = session.udtf.register(\n",
    "    name = \"UDTF_MODEL_INF_v1\",\n",
    "    replace=True,\n",
    "    handler=UDTF_Model_Train, # the class\n",
    "    input_types=[PandasDataFrameType([FloatType(),FloatType(),FloatType(),FloatType(),FloatType(),\n",
    "                                      DateType(), IntegerType(), StringType(), IntegerType(), IntegerType()])], \n",
    "    output_schema=PandasDataFrameType([DateType(), IntegerType(), FloatType(), StringType(), IntegerType(), FloatType()],\n",
    "                                      [\"DATE\",\"HH\",\"ACTUAL\",\"GEO\",\"CONTRACT_ID\", \"FORECAST\"]), # note these are not appended with _ \n",
    "    packages=[\"snowflake-snowpark-python\", 'pandas', 'snowflake-ml-python'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "45a4de4b-4ec2-4825-a1d1-225d9055cf64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('COL0', 'double'),\n",
       " ('COL1', 'double'),\n",
       " ('COL2', 'double'),\n",
       " ('COL3', 'double'),\n",
       " ('COL4', 'double'),\n",
       " ('DATE', 'date'),\n",
       " ('HH', 'bigint'),\n",
       " ('GEO', 'string(16777216)'),\n",
       " ('CONTRACT_ID', 'bigint'),\n",
       " ('ACTUAL', 'bigint')]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf = session.table('v1')\n",
    "sdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "04a5cd9f-8b69-4637-a722-ab5794638ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# syntax is, say the columns you want to go in ( the *[] bit below), and say what partitions you want to cut the data up by ( in this case CONTRACT_ID)\n",
    "sdf_prepped = sdf.select(udtf_model_inf(*['COL0', 'COL1', 'COL2', 'COL3', 'COL4', 'DATE', 'HH', 'GEO', 'CONTRACT_ID', 'ACTUAL']).over(partition_by=['CONTRACT_ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5f7c8eb6-a8b4-4270-b930-b83148a5d901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "|\"DATE\"      |\"HH\"  |\"ACTUAL\"  |\"GEO\"  |\"CONTRACT_ID\"  |\"FORECAST\"  |\n",
      "---------------------------------------------------------------------\n",
      "|2018-01-01  |2     |1.0       |3      |4              |1.0         |\n",
      "|2018-01-01  |1     |0.0       |0      |4              |0.0         |\n",
      "|2018-01-01  |1     |1.0       |1      |4              |1.0         |\n",
      "|2018-01-01  |3     |0.0       |0      |4              |0.0         |\n",
      "|2018-01-01  |2     |0.0       |0      |4              |0.0         |\n",
      "|2018-01-01  |1     |1.0       |2      |4              |1.0         |\n",
      "|2018-01-01  |4     |1.0       |3      |4              |1.0         |\n",
      "|2018-01-01  |0     |1.0       |4      |4              |1.0         |\n",
      "|2018-01-01  |2     |1.0       |2      |4              |1.0         |\n",
      "|2018-01-01  |3     |0.0       |4      |4              |0.0         |\n",
      "---------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_prepped.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3bac86-df4a-4068-9f6d-1105ce40d500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
